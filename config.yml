# Relevant file/directory paths
PATHS:
  RAW_DATA: 'data/raw/HIFIS_Clients.csv'
  RAW_SPDAT_DATA: 'data/raw/SPDATS.json'
  PROCESSED_DATA: 'data/processed/HIFIS_Processed.csv'
  PROCESSED_OHE_DATA: 'data/processed/HIFIS_Processed_OHE.csv'
  GROUND_TRUTH: 'data/processed/GroundTruth.csv'
  DATA_INFO: 'data/interpretability/data_info.yml'
  MODEL_WEIGHTS: 'results/models/'
  MODEL_TO_LOAD: 'results/models/model.h5'
  IMAGES: 'documents/generated_images/'
  LOGS: 'results/logs/'
  EXPERIMENTS: 'results/experiments/'
  HORIZON_SEARCH: 'results/experiments/horizon_search'
  LIME_EXPERIMENT: 'results/experiments/lime_experiment'
  LIME_SUBMODULAR_PICK: 'results/experiments/lime_submodular_pick.csv'
  TRAIN_SET: 'data/processed/Train_Set.csv'
  VAL_SET: 'data/processed/Val_Set.csv'
  TEST_SET: 'data/processed/Test_Set.csv'
  SCALER_COL_TRANSFORMER: 'data/transformers/scaler_col_transformer.bin'
  ORDINAL_COL_TRANSFORMER: 'data/transformers/ordinal_col_transformer.bin'
  OHE_COL_TRANSFORMER_MV: 'data/transformers/ohe_col_transformer_mv.bin'
  OHE_COL_TRANSFORMER_SV: 'data/transformers/ohe_col_transformer_sv.bin'
  MULTI_TRAIN_TEST_METRICS: 'results/experiments/multi_train_test_metrics.csv'
  LIME_EXPLAINER: './data/interpretability/explainer.pkl'
  BATCH_PREDICTIONS: './results/predictions/predictions'
  TRENDING_PREDICTIONS: './results/predictions/trending_predictions.csv'
  K-PROTOTYPES_CENTROIDS: 'results/experiments/cluster_centroids_'
  K-PROTOTYPES_CLUSTERS: 'results/experiments/client_clusters_'

# Constants pertaining to data structure
DATA:
  N_WEEKS: 26
  GROUND_TRUTH_DATE: 'today'   # Set to either 'today' or a past date with format 'yyyy-mm-dd'
  CHRONIC_THRESHOLD: 180
  CLIENT_EXCLUSIONS: []
  FEATURES_TO_DROP_FIRST: ['MovedInDate','OtherMedications','DietCatetory','FoodType',
                           'ConsentType','ClientHeightCM','EyeColour','HairColour','ProvinceOfBirth','CityOfBirth','CountryOfBirth',
                           'IntakeID', 'clientContributingFactorID', 'ClientBehaviouralFactorID', 'PeopleLifeEventID',
                            'ClientDietID', 'ClientBarredPeriodID', 'Modules', 'ServiceRestricitonOrganizationName', 'PersonID']
  IDENTIFYING_FEATURES_TO_DROP_LAST: ['ServiceID','FamilyID','MonthlyAmount','DOB']
  TIMED_FEATURES_TO_DROP_LAST: ['DateEnd']
  TIMED_EVENTS: ['Behavioral Risk Factor', 'Contributing Factor', 'Diet', 'Education', 'Expenses', 'HealthIssues', 'Income', 'Life Events',
                 'Medications', 'Service Restriction', 'VAT', 'VISPDAT']
  TIMED_SERVICE_FEATURES: ['Stay', 'Case Management', 'Housing', 'Housing Subsidy', 'Storage']
  COUNTED_SERVICE_FEATURES: ['Reservations', 'Turnaways', 'Food Bank', 'Goods and Services', 'SPDAT']
  NONCATEGORICAL_FEATURES: ['ServiceID','ClientID','FamilyID','DateStart', 'DateEnd','CurrentAge','ClientHeightCM',
                            'ClientWeightKG','MonthlyAmount', 'ExpenseAmount','TotalScore']
  CATEGORICAL_FEATURES: ['ConsentType', 'RelationshipType', 'Gender', 'AboriginalIndicator', 'Citizenship', 'VeteranStatus', 'CountryOfBirth',
                         'ProvinceOfBirth', 'CityOfBirth', 'HairColour', 'EyeColour', 'ServiceType', 'OrganizationName', 'ReasonForService',
                         'InHousing', 'IncomeType', 'ExpenseType', 'ExpenseFrequency', 'IsEssentialYN', 'EducationLevel', 'HealthIssue', 'DiagnosedYN',
                         'SelfReportedYN', 'SuspectedYN', 'OtherMedications', 'ContributingFactor', 'BehavioralFactor',
                         'Severity', 'LifeEvent', 'DietCatetory', 'FoodType', 'PreScreenPeriod', 'Reason']
  KFOLDS: 10
  TIME_SERIES:
    TIME_STEP: 30                        # In days
    T_X: 6                               # Length of time series input sequence
    YEARS_OF_DATA: 3                     # Years of recent data to create time series records for.
    FOLDS: 10
  SPDAT:
    INCLUDE_SPDATS: false
    SPDAT_CLIENTS_ONLY: false
    SPDAT_DATA_ONLY: false

# Neural network models
MODELS:
  HIFIS_MLP:
    NODES:
      DENSE0: 80
      DENSE1: 60
    LAYERS: 3
    L2_LAMBDA: 0.01
    DROPOUT: 0.35
    LR: 0.0001
  HIFIS_RNN_MLP:
    LSTM:
      UNITS: 4
    DENSE:
      DENSE0: 32
      DENSE1: 16
    LAYERS: 6
    L2_LAMBDA: 0.0023
    DROPOUT: 0.41
    LR: 0.001
  LOGISTIC_REGRESSION:
  RANDOM_FOREST:
    N_ESTIMATORS: 100
  XGBOOST:
    N_ESTIMATORS: 100

# Training
TRAIN:
  EXPERIMENT: 'single_train'         # One of {'single_train', 'multi_train', 'hparam_search', 'cross_validation'}
  MODEL_DEF: 'hifis_rnn_mlp'           # One of {'hifis_mlp', 'hifis_rnn_mlp', 'logistic_regression', 'random_forest', 'xgboost'}
  TRAIN_SPLIT: 0.9
  VAL_SPLIT: 0.05
  TEST_SPLIT: 0.05
  EPOCHS: 300
  BATCH_SIZE: 1024
  POS_WEIGHT: 0.5
  IMB_STRATEGY: 'none'                   # One of {'class_weight', 'random_oversample', 'smote', 'adasyn', 'none'}
  METRIC_PREFERENCE: ['recall', 'f1score', 'precision', 'auc', 'loss', 'accuracy']
  NUM_RUNS: 150
  THRESHOLDS: [0.3, 0.4, 0.5, 0.6, 0.7]  # Can be changed to list of values in range [0, 1]
  PATIENCE: 15
  DATASET_TYPE: 'static_and_dynamic'                 # One of 'static', 'static_and_dynamic'
  HP:
    METRICS: ['accuracy', 'loss', 'recall', 'precision', 'auc']
    COMBINATIONS: 100
    REPEATS: 2
    RANGES:
      NODES0: [32, 64, 128]                  # Discrete range
      NODES1: [16, 32, 64]                  # Discrete range
      LAYERS: [2, 4, 6]                     # Discrete range
      DROPOUT: [0.2, 0.5]                   # Real range
      LR: [-3.0, -3.0]                      # Real range on logarithmic scale (10^x)
      OPTIMIZER: ['adam']                   # Discrete range
      BETA_1: [-1.0, -1.0]                  # 1st moment for Adam. Real range on log scale (1 - 10^x)
      BETA_2: [-3.0, -3.0]                  # 2nd moment for Adam. Real range on log scale (1 - 10^x)
      L2_LAMBDA: [-7.0, -2.0]               # Real range on log scale (10^x)
      BATCH_SIZE: [1024]                    # Discrete range
      POS_WEIGHT: [0.5, 0.5]                # Weight multiplier for positive class. Real range
      IMB_STRATEGY: ['class_weight']        # Discrete range
      LSTM_UNITS: [4, 8, 16, 32]            # Discrete range


# LIME explanations
LIME:
  HIFIS_MLP:
    KERNEL_WIDTH: 2.5
    FEATURE_SELECTION: 'lasso_path'
    NUM_FEATURES: 15
    NUM_SAMPLES: 60000
    MAX_DISPLAYED_RULES: 15
  HIFIS_RNN_MLP:
    KERNEL_WIDTH: 'default'
    FEATURE_SELECTION: 'lasso_path'
    NUM_FEATURES: 30
    NUM_SAMPLES: 40000
    MAX_DISPLAYED_RULES: 30
  SP:
    SAMPLE_FRACTION: 0.2
    NUM_EXPLANATIONS: 15
  EXPERIMENT: 'explain_client'               # One of {'explain_client', 'lime_experiment', 'submodular_pick'}

# Predictive horizon search experiment
HORIZON_SEARCH:
  N_MIN: 0
  N_MAX: 52
  N_INTERVAL: 13

# Batch predictions on raw data
PREDICTION:
  THRESHOLD: 0.5


  CLASS_NAMES: {0: 'not at risk', 1: 'at risk'}
  EXPERIMENT: 'batch_prediction'              # One of {'batch_prediction', 'trending_prediction'}

# Data clustering
K-PROTOTYPES:
  K: 4
  N_RUNS: 15
  N_JOBS: 5
  K_MIN: 2
  K_MAX: 20
  EXPERIMENT: 'cluster_clients'               # One of {'cluster_clients', 'silhouette_analysis'}